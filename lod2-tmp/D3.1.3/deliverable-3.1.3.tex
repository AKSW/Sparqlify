\documentclass[a4paper,twoside,bibtotoc,abstracton,12pt,BCOR=15mm]{scrreprt}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{moreverb}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{array}
\usepackage{url}
\usepackage{lscape}
\usepackage{rotating,makecell}
\usepackage{pdfpages}
\usepackage{listings} 
\usepackage{fancyhdr}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{pdflscape}
%\usepackage[table]{xcolor}
%\usepackage{amsthm}
\usepackage[font=small,labelfont=bf,tableposition=top]{caption}
\usepackage[font=footnotesize]{subcaption}
\usepackage{algorithmic}
\usepackage{paralist}

%\usepackage[table]{xcolor}
%\usepackage{todonotes}

\newenvironment{example}{}
 
\DeclareGraphicsExtensions{.png,.pdf,.eps} 

% listing styles
\lstset{numbers=left, numberstyle=\tiny,basicstyle=\ttfamily\scriptsize, tabsize=2, keywordstyle=\underbar, stringstyle=\small, backgroundcolor=\color[gray]{0.94}, framexleftmargin=2pt}
\lstdefinestyle{rdfa}{numberblanklines=true, morekeywords={}}

\lhead{LOD2 (222011)}
\chead{}
\rhead{Triplify Tool Release}
\lfoot{Deliverable 3.1.3}
\cfoot{}
\rfoot{Page \thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}


\newcommand{\todo}[1]{\textbf{ToDo: \textit{#1}}}


\pagestyle{fancy}

\graphicspath{{images/}}



%\newcommand{\prefixurl}[1]{\url{http://meta.wikimedia.org/wiki/DBpedia/ontology/#1}}
\begin{document} 


% \includepdf{cover-page}
\includepdf{cover_page}

% edit history
\include{history}

\tableofcontents

\chapter*{Introduction}
\emph{Sparqlify} is a novel SPARQL-SQL query rewriter that greatly simplifies the definition of RDF views thanks to the intuitive
\emph{Sparqlify Mapping Language} (Sparqlify-ML).
Whereas most current mapping approaches use RDF and XML as a means to represent the mapping information,
Sparqlify mappings are expressed as view definitions based on the \emph{SPARQL} grammar\footnote{\url{http://www.w3.org/TR/rdf-sparql-query/\#sparqlGrammar}} that has been
extended with a few custom production rules (see \autoref{sec:spec:sparqlify-ml-syntax}).
As such, users that know SPARQL are already familiar with most of Sparqlify's syntactic elements.
The remainder of this report is divided into two parts:
The first one describes Sparqlify from a user's perspective, i.e. how
to setup the system and create custom mappings. 
The second part is then dedicated to technical details. 


\chapter{User's manual}
In this chapter we explain how to obtain, configure and launch the Sparqlify server and, further, 
how to write RDF views for relational databases.
We also describe example use-cases and best practices.

\section{Obtaining Sparqlify}
Sparqlify is written in \emph{Java} and the source code is available on \emph{Github} at \url{https://github.com/AKSW/Sparqlify}.
At this page we also provide downloads of pre-built jars.

\subsection{Building Sparqlify from Source}
For the latest features and bug-fixes you may want to build Sparqlify from source.
\begin{itemize}
\item First, clone the repository:
\begin{lstlisting}
git clone git://github.com/AKSW/Sparqlify.git
\end{lstlisting}

\item Run the following command in the root directory of the cloned repository:
\begin{lstlisting}
mvn assembly:assembly
\end{lstlisting}
This will create a jar file containing the main class and all necessary dependencies at the location \texttt{target/sparqlify-\{version\}-jar-with-dependencies.jar}

\item For convenience, create a script named \texttt{sparqlify} with the following content:
\begin{lstlisting}
#!/bin/sh
java -cp target/sparqlify-0.0.1-SNAPSHOT-jar-with-dependencies.jar \
    RunEndpoint $@
\end{lstlisting}
Note: Adjust the name of the sparqlify jar according to your built or downloaded file name.

\item Finally, make the script executable:
\begin{lstlisting}
chmod +x sparqlify
\end{lstlisting}
\end{itemize}

\subsection{The LOD2 Stack Debian Package}
Sparqlify is also available as a LOD2 Stack Debian package.
\begin{itemize}
\item If you have not set up the LOD2 repository yet, run
\begin{lstlisting}
wget http://stack.lod2.eu/lod2repository_current_all.deb
dpkg -i lod2repository_current_all.deb
sudo apt-get update
\end{lstlisting}

\item Sparqlify itself is installed using:
\begin{lstlisting}
sudo apt-get install sparqlify
\end{lstlisting}
This package makes the ``sparqlify'' command available on the system.
\end{itemize}
 
\section{Running the Sparqlify Server}
The Sparqlify server is run from the command line.
Note: Deployment using an application server, such as Tomcat or Glassfish, is not yet supported. 
\begin{verbatim}
sparqlify.sh [options]
\end{verbatim}

Options are:
\begin{itemize}
  \item Server Configuration
	\begin{itemize}
        \item[-c] Sparqlify-ML config file
        \item[-P] Server port [default: 7531]
    \end{itemize}

  \item Database Settings
	\begin{itemize}
      \item[-h] Hostname of the database [default: localhost]\newline
      port can also be specified, e.g. \texttt{localhost:5432}
      \item[-d] Database name
      \item[-u] User name
      \item[-p] Password
	\end{itemize}
	
  \item Quality of Service
    \begin{itemize}
      \item[-n] Maximum result set size
      \item[-t] Maximum query execution time in seconds (excluding rewriting
      time)
    \end{itemize}
\end{itemize}

\noindent Example usage:
\begin{lstlisting}
sparqlify -c my-mappings.sparqlify  -h localhost:5432 \
    -d employee-database -u postgres -p secret -n 1000 -t 30 
\end{lstlisting}

The Sparqlify-ML config file contains the view definitions as explained in the subsequent sections
\autoref{sec:sparqlify-ml-intro} and \autoref{sect:sparqlify-config-file}. 

\noindent When starting the server, a standard SPARQL endpoint will be available at the specified server port.
This can be tested for example with \texttt{curl}.
\begin{lstlisting}
curl http://localhost:7531/sparql?query=Select+%2A+%7B+%3Fs+%3Fp+%3Fo+%7D+Limit+10
\end{lstlisting}

\noindent Note that currently no HTML front-end is integrated into Sparqlify.
However, a tool such such as SNORQL\footnote{\url{https://github.com/kurtjx/SNORQL}} can be set up for providing this functionality.


\section{Introduction to the Sparqlify Mapping Language}
\label{sec:sparqlify-ml-intro}

The Sparqlify Mapping Language (Sparqlify-ML) allows to describe how an RDB-RDF mapping system should construct RDF
quads (graph, subject, predicate, object) from a \emph{logical table}. 
The term logical table thereby refers to anything for which a tabular representation can be obtained, i.e. an SQL table, an SQL view or an SQL SELECT statement.
It is important to note that the aim of the section is to give users an informal impression of the mapping language.
For this reason the focus lies on the description of how RDF data is created from logical tables using Sparqlify-ML.
If you are interested in formal aspects of the mapping language or the process of rewriting SPARQL queries to SQL, please refer to
the technical documentation in~\autoref{sec:tech-doc}.
In the following we introduce the core concepts of Sparqlify-ML based on an example.
\begin{figure}[!p] % has been [!h] before
\centering
\begin{tabular}{p{6.5cm}p{8.5cm}}
\toprule
(a) Table & (b) Sparqlify Mapping \\ 
\midrule

\begin{tabular}{|l|l|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{Employee} \\ \hline
\textbf{id} & \textbf{name} & \textbf{workpage} & \textbf{age} \\ \hline
1 & Anne & http://ex.org/a  & 30 \\ \hline
2 & John & http://ex.org/j  & 40 \\ \hline
%3 & Tim  & Tucker & 25 \\ \hline
\end{tabular}

&

\begin{minipage}{8.5cm}
\begin{scriptsize}
\begin{verbatim}
Prefix ex: <http://ex.org/>
Prefix foaf: <http://xmlns.com/foaf/0.1/>
Create View MyRdfView_for_Employee As
  Construct {
    ?s a ex:Employee .
    ?s foaf:name ?name .
    ?s foaf:workpage ?wp .
    ?s foaf:age ?age .
  }
  With
    ?s = uri(concat("http://ex.org/employee/", ?id))
    ?name = plainLiteral(?name)
    ?wp = uri(?workpage)
    ?age = typedLiteral(?age, xsd:int)
 Constrain
     ?wp prefix "http://ex.org/"
 From
    Employee
\end{verbatim}
\end{scriptsize}
\end{minipage}


\\

\multicolumn{2}{l}{(c) Resulting RDF} \\ \midrule
\begin{minipage}{\textwidth}
\begin{lstlisting}
@prefix ex: <http://ex.org/> .
@prefix foaf: <http://xmlns.com/foaf/0.1/> .

<http://ex.org/employee/1> a ex:Employee ;
    foaf:name "Anne" ;
    foaf:workpage <http://ex.org/a> ;
    foaf:age "30"^^xsd:int .

<http://ex.org/employee/2> a ex:Employee ;
    foaf:name "John" ;
    foaf:workpage <http://ex.org/j> ;
    foaf:age "40"^^xsd:int .

\end{lstlisting}
\end{minipage}


\\
\bottomrule
\end{tabular}
\caption{Mapping example with employees.}
\label{fig:ex:mapping:employee}
\end{figure}
In~\autoref{fig:ex:mapping:employee} these are presented, namely:
\begin{itemize} 
\item a relation holding information about employees,
\item a Sparqlify-ML view definition and 
\item the corresponding RDF data a system should generate.
\end{itemize}
The RDF is obtained by applying the Sparqlify-ML mapping for each row of the employees table.
The Sparqlify-ML view definition is composed of three clauses, namely \emph{Construct}, \emph{With} and \emph{From},
which are explained in the following.

The \emph{From} clause specifies the logical table from which to obtain the rows that should be mapped.
In our example, it refers to the physical table or view named \emph{employee}.
Note that SQL queries can be directly
specified in the \emph{From} clause by escaping them with double brackets:
\begin{lstlisting}
...
   From
      [[Select id, name, age From employee]]
\end{lstlisting}

The \emph{With} clause is used to declare how to generate RDF terms from (expressions over) the columns of the \emph{logical table} and
how to associate these RDF terms with SPARQL variables.
As such, the \emph{With} clause is the bridge between the relational and the RDF data models.
The variables on the left-hand side of the \texttt{=}-sign can be referenced in the \emph{Construct} clause, whereas
the "variables" on the right-hand side are actually interpreted as names referring to the columns of the \emph{logical table}.

Formally, the \emph{With} clause contains a set of \emph{variable bindings}, which are expressions of the form \texttt{sparql-var = rdf-term-constructor(args)}.
The \emph{RDF term constructors} are function symbols for constructing RDF terms, i.e. blank nodes, URIs, plain and typed literals, from the \emph{logical table}.
The corresponding parameters are as follows:
\begin{itemize}
  \item $blankNode(x)$: Creates a blank node with $x$ as identifier.
  \item $uri(x)$:  Creates a URI from the value of $x$.
  \item $plainLiteral(x, y)$: Creates a plain literal with value $x$ and language tag $y$.
  \item $plainLiteral(x)$: Creates a plain literal with value $x$ and without language tag.
  \item $typedLiteral(x, y)$: Creates a typed literal with value $x$ and data type $y$. 
\end{itemize}
Note that there is also the RDF term constructor \emph{rdfTerm} which is a wrapper around all the above constructors.
It takes the form \texttt{rdfTerm(type, value, datatype, language)}, with datatype and language being optional parameters.

The arguments $x$ and $y$ are expressions composed of the following elements:
\begin{itemize}
           \item Constants; numeric values or strings.
           		Single and double quotes can be used for escaping strings. 
           \item Column references, i.e. column-names preceded by a question mark, such as \emph{?column-name}.
           \item \emph{concat}(varargs): Concatenation of any number of arguments. Non-string arguments will be converted to string.
           \item \emph{urlEncode}(expr)
           \item \emph{urlDecode}(expr)
           \item \emph{Arithmetic operators}: +, -, *, /
\end{itemize}
           
The \emph{Construct} clause specifies an RDF template. 
For each row of the underlying table, the \emph{With} clause is evaluated.
This in turn yields the variable-value bindings for instantiating the template in order to obtain the final RDF graph.
  
The \emph{Constraint} clause does not have a direct influence on the RDF generation. 
A Sparqlify-ML processor may consider the provided constraints in order to apply certain optimizations.
Currently, Sparqlify-ML only offers a \emph{prefix} constraint, which applies to URIs and whose 
syntax is: \texttt{sparql-var PREFIX string [, string]*}.
This constraint indicates, that all URIs that will be generated and bound to \texttt{sparql-var} will only carry the specified prefixes.
By this a Sparqlify-ML processor may for instance rule out joins between variables which do not share any prefixes.
Note, that incorrectly specified constraints may result in missing data.
  
A Sparqlify-ML processor may provide means to validate the given constraints.


\subsection{Sparqlify Config File}
\label{sect:sparqlify-config-file}
A Sparqlify configuration file, as required by the \texttt{-c} option of the Sparqlify server, is composed of a set of statements
which can be standard SPARQL prefix declarations and Sparqlify view definitions.
A prefix declaration is valid throughout the whole file, so any number of view definitions may reference the declared prefixes.
Additionally, the Sparqlify system will use the prefixes appropriately when returning RDF data, such as TURTLE responses to SPARQL CONSTRUCT queries.    
The syntax is specified in \autoref{sec:spec:sparqlify-ml-syntax}.

Examples of mapping files are available in the source code repository, at \url{http://https://github.com/AKSW/Sparqlify/tree/master/mappings}.

\newpage
\section{View definition examples}
In this section we provide a collection of view definition examples motivated by different use cases.

\subsection{Mapping data into distinct graphs}
\begin{figure}[!h]
\centering
\begin{tabular}{p{5.5cm}p{8.5cm}}
\toprule
Table & Sparqlify Mapping \\ 
\midrule

\begin{tabular}{|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{tags} \\ \hline
\textbf{id} & \textbf{name} \\ \hline
1 & image \\ \hline
2 & document \\ \hline
\end{tabular}

&

\begin{minipage}{8.5cm}
\begin{scriptsize}
\begin{verbatim}
Prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>
Prefix owl: <http://www.w3.org/2002/07/owl#>
Create View GraphDemo As
  Construct {
    Graph <http://ex.org/owl> {
        ?s a owl:Class
    }
    
    Graph <http://ex.org/rdfs> {
        ?s a rdfs:Class
    }    
  }
  With
    ?s = uri(concat("http://ex.org/thing/", urlEncode(?name)))
  From
    tags
\end{verbatim}
\end{scriptsize}
\end{minipage}


\\

\multicolumn{2}{l}{Resulting RDF} \\ \midrule
\begin{minipage}{\textwidth}
\begin{lstlisting}
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .

Graph <http://ex.org/owl> {
    http://ex.org/thing/image> a owl:Class .
    http://ex.org/thing/document> a owl:Class .
}

Graph <http://ex.org/rdfs> {
    http://ex.org/thing/image> a rdfs:Class .
    http://ex.org/thing/document> a rdfs:Class .
}
\end{lstlisting}
\end{minipage}

\\
\bottomrule
\end{tabular}
\caption{Mapping data into distinct graphs.}
\label{fig:ex:mapping:distinctgraphs}
\end{figure}

Note that variables are also allowed as graph names.

\newpage
\subsection{Language tags from table columns}
If a database table already has a column containing valid RDF language tags, the column name can be used directly in the plainLiteral term constructor,
as shown in \autoref{fig:ex:mapping:language_tags}
\begin{figure}[!h]
\centering
\begin{tabular}{p{5.5cm}p{8.5cm}}
\toprule
Table & Sparqlify Mapping \\ 
\midrule

\begin{tabular}{|l|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{translations} \\ \hline
\textbf{id} & \textbf{name} & \textbf{language} \\ \hline
1 & image & en \\ \hline
1 & Bild & de \\ \hline
\end{tabular}

&

\begin{minipage}{8.5cm}
\begin{scriptsize}
\begin{verbatim}
Prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>
Create View LanguageTagDemo As
  Construct {
      ?s rdfs:label ?o .
  }
  With
    ?s = uri(concat("http://ex.org/translation/", ?id))
    ?o = plainLiteral(?name, ?language)
  From
    translations
\end{verbatim}
\end{scriptsize}
\end{minipage}


\\

\multicolumn{2}{l}{Resulting RDF} \\ \midrule
\begin{minipage}{\textwidth}
\begin{lstlisting}
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .

<http://ex.org/translation/1> rdfs:label "image"@en, "Bild"@de .
\end{lstlisting}
\end{minipage}


\\
\bottomrule
\end{tabular}
\caption{Mapping language tags from columns.}
\label{fig:ex:mapping:language_tags}
\end{figure}



\newpage
\subsection{Mapping spatial data}
Mapping spatial data to RDF using Sparqlify-ML works exactly the same as mapping conventional data.
The burden of obtaining proper RDF representations for values of geographic datatypes is transferred to the Sparqlify-ML processor.

\begin{figure}[!h]
\centering
\begin{tabular}{p{5.5cm}p{8.5cm}}
\toprule
Table & Sparqlify Mapping \\ 
\midrule

\begin{tabular}{|l|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{point\_of\_interest} \\ \hline
\textbf{id} & \textbf{type} & \textbf{geom} \\ \hline
1 & lgdo:Bakery & (1, 1) \\ \hline
2 & lgdo:School & (2, 2) \\ \hline
3 & lgdo:Pub    & (3, 3) \\ \hline
\end{tabular}

&

\begin{minipage}{8.5cm}
\begin{scriptsize}
\begin{verbatim}
Prefix geom: <http://geovocab.org/geometry#>
Prefix lgdo: <http://linkedgeodata.org/ontology/>
Create View points As
    Construct {
        ?s a ?t .
        ?s geom:geometry ?geo .
    }
    With
        ?s = uri(concat("http://ex.org/", ?id))
        ?t =  uri(?type)
        ?geo = typedLiteral(?geom, ogc:WKTLiteral)
    From
        point_of_interest
\end{verbatim}
\end{scriptsize}
\end{minipage}

\\

\multicolumn{2}{l}{Resulting RDF} \\ \midrule
\begin{minipage}{\textwidth}
\begin{lstlisting}
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix geom: <http://geovocab.org/geometry#> .
@prefix ogc: <http://ogp.me/ns/class#> .

<http://ex.org/1> rdf:type <http://linkedgeodata.org/ontology/Bakery> .
<http://ex.org/2> rdf:type <http://linkedgeodata.org/ontology/School> .
<http://ex.org/2> rdf:type <http://linkedgeodata.org/ontology/Pub> .
<http://ex.org/1> geom:geometry "POINT(1, 1)"^^ogc:WKTLiteral .
<http://ex.org/2> geom:geometry "POINT(2, 2)"^^ogc:WKTLiteral .
<http://ex.org/3> geom:geometry "POINT(3, 3)"^^ogc:WKTLiteral .
\end{lstlisting}
\end{minipage}
\\
\bottomrule
\end{tabular}
\caption{Mapping spatial data.}
\label{fig:ex:mapping:spatial-data}
\end{figure}


\newpage
\section{Mapping CSV files}
The Sparqlify code base also offers the \texttt{sparqlify-csv} command line tool for mapping CSV files to RDF.
The view definition syntax is essentially Sparqlify-ML with the following differences:
\begin{itemize}
  \item View definitions require the use of an additional \texttt{template} keyword: \texttt{Create View Template viewname As Construct\ldots}
  \item There are no FROM and CONSTRAINT clauses.
\end{itemize}
\autoref{fig:ex:sparqlify-csv} shows an example of such CSV-RDF mapping.


\begin{figure}[!h]
\centering
\begin{tabular}{p{6cm}p{8.5cm}}
\toprule
Table & Sparqlify Mapping \\ 
\midrule

\begin{scriptsize}
\begin{tabular}{|l|l|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{tags} \\ \hline
\textbf{city} & \textbf{country} & \textbf{long} & \textbf{lat} \\ \hline
Leipzig & Germany & 12.383333 & 51.33333 \\ \hline
\end{tabular}
\end{scriptsize}

&

\begin{minipage}{8.5cm}
\begin{scriptsize}
\begin{verbatim}
Prefix lgdo: <http://linkedgeodata.org/ontology/>
Prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>
Prefix geo: <http://www.w3.org/2003/01/geo/wgs84_pos#>
Prefix xsd: <http://www.w3.org/2001/XMLSchema#>
Prefix fn: <http://aksw.org/sparqlify/>
Create View Template geocode As
  Construct {
    ?cityUri
      a lgdo:City ;
      rdfs:label ?cityLabel ;
      geo:long ?long ;
      geo:lat ?lat .
  }
  With
    ?cityUri =
      uri(concat(
         "http://ex.org/",
         fn:urlEncode(?2), "-", fn:urlEncode(?1)))
    ?cityLabel = plainLiteral(?1)
    ?long = typedLiteral(?3, xsd:float)
    ?lat = typedLiteral(?4, xsd:float)
\end{verbatim}
\end{scriptsize}
\end{minipage}


\\

\multicolumn{2}{l}{Resulting RDF} \\ \midrule
\begin{minipage}{\textwidth}
\begin{lstlisting}
@prefix rdfs:<http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd:<http://www.w3.org/2001/XMLSchema#> .
@prefix geo:<http://www.w3.org/2003/01/geo/wgs84_pos#> .

<http://ex.org/Germany-Leipzig>
    rdfs:label "Leipzig" ;
    geo:long "12.383333"^^xsd:float ;
    geo:lat "51.33333"^^xsd:float .
\end{lstlisting}
\end{minipage}

\\
\bottomrule
\end{tabular}
\caption{Converting CSV data to RDF using the sparqlify-csv utility.}
\label{fig:ex:sparqlify-csv}
\end{figure}

\paragraph{Running sparqlify-csv}
If the Debian package was installed, the following command will be available system wide:
\begin{lstlisting}
sparqlify-csv [options]
\end{lstlisting}

Alternatively, \texttt{sparqlify-csv} is run form the JAR as shown below:
\begin{lstlisting}
java -cp target/sparqlify-{version}-jar-with-dependencies.jar \
    org.aksw.sparqlify.csv.CsvMapperCliMain [options]
\end{lstlisting}

\paragraph{Options}
\begin{itemize}
  \item[-f] \texttt{file} The CSV file to map. Currently must be Excel flavour; for instance tabs will currently not work.
  \item[-c] \texttt{file} The Sparqlify mapping file containing the 'Create View Template ...' statements.
  \item[-v] \texttt{view\_name} If the mapping file (given as the -c option) contains more than one view, the name of the view to use for the mapping must be specified.
  \item[-h] Specifying this flag causes the first row of the CSV file to be treated as headers (i.e. column names). In this case, columns can be referenced by both name and index.
\end{itemize}

Columns can be referenced by name (see the -h option) and/or by index (1-based).

\paragraph{Example}
\begin{lstlisting}[caption=Example Invocation of the sparqlify-csv tool]
sparqlify-csv -f data.csv -c mappings.sparqlify -v myview
\end{lstlisting}

Any RDF data will be written to STDOUT in the N-TRIPLES format. Log output is written to STDERR.




\chapter{Technical documentation}
\label{sec:tech-doc}
In this section we first introduce some fundamental concepts and observations that were considered during the development of Sparqlify. 
Subsequently, we explain the rewriting process from SPARQL to SQL in detail.
Some things that are noteworthy in advance are:
\begin{itemize}
  \item All modern RDF stores operate on quads; so does Sparqlify.
		For this reason we also base our discussion on quads and quad patterns and do not bother with triples and triple patterns.
		In all cases where only triples are shown, one should assume these triples to actually be quads with their graph set to Jena's default graph constant
		\url{urn:x-arq:DefaultGraph}, abbreviated as \texttt{:g}, 
  \item Likewise, we also define an RDF graph as a set of quads.
		In order to avoid confusion, we emphasize that the term \emph{RDF graph} --- despite being called ``graph'' --- is formally actually a quadrivalent relation.
        Throughout this section we make use of notions such as ``Select \{ ?g ?s ?p ?o \}'' which should be considered to refer to quads.      
  \item At present, Sparqlify translates a SPARQL query into a single SQL query.
  \item The term SPARQL-SQL rewriting is somewhat imprecise, because the target artefact of the rewrite is not an SQL query alone: In the case of Sparqlify, the \emph{two}
        artefacts are the \emph{SQL} query and a \emph{mapping} of how to construct a SPARQL result set from the corresponding SQL result set.
        This mapping is similar to that of the Sparqlify-ML variable bindings and will be discussed in more detail throughout this chapter.
        In general, one could see the target artefact of a a SPARQL-SQL rewrite as a query query execution plan where e.g. joins and unions can happen either in the SPARQL-SQL engine or the underlying relational database.
        Such query plan would then use the SQL queries + mappings as building blocks for more complex operations such as in-memory joins.
        From this point of view, Sparqlify's result artefact can be seen as a single-node query execution plan:
   \item One SPARQL query is translated into exactly one (SQL-query, mapping) pair.
\end{itemize}


\section{Running Example}
This section introduces a simple example which is used for demonstrating the stages of the query translation.
\autoref{fig:running_example} shows two Sparqlify-ML views and
corresponding relations. One maps URIs to type URIs, the other maps URIs to literal comments.
The query was chosen as it demonstrates a case where a quad \texttt{(:g ?s ?t ?s)} implicitly constrains its own terms (the subject and object position need to be equal)
without an additional filter statement. Note that the default graph URIs have been omitted for brevity in both the view and the query.
Also note, that each column referenced by the variable binding carries a datatype which must be taken into account during the rewriting.  

\begin{figure}[!h]
\centering
\begin{tabular}{lll}
\toprule
\emph{Query} & \emph{Types View} & \emph{Comments View} \\ 
\midrule

\begin{minipage}{4.5cm}
\begin{scriptsize}
\begin{verbatim}
Select Distinct ?s ?o {
  ?s ?t ?s .
  ?s rdfs:comment ?o .
}
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{4cm}
\begin{scriptsize}
\begin{verbatim}
Create View types As
  Construct {
     ?x rdf:type ?y .
  } With
     ?x = uri(?ts)
     ?y = uri(?to)
  From
    sql_types
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{5cm}
\begin{scriptsize}
\begin{verbatim}
Create View comments As
  Construct {
     ?h rdfs:comment ?i .
  } With
     ?h = uri(?cs)
     ?i = plainLiteral(?co)
  From
    sql_comments
\end{verbatim}
\end{scriptsize}
\end{minipage}

\\

\begin{minipage}{4.5cm}
\begin{scriptsize}
\begin{tabular}{|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{Result Set} \\ \hline
\textbf{s} & \textbf{o} \\ \hline
rdfs:Class & "Class of classes" \\ \hline
\end{tabular}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{4cm}
\begin{scriptsize}
\begin{tabular}{|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{sql\_types} \\ \hline
\textbf{ts} & \textbf{to} \\ \hline
rdfs:Class & rdfs:Class \\ \hline
ex:car123 & ex:Car \\ \hline
\end{tabular}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{5cm}
\begin{scriptsize}
\begin{tabular}{|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{sql\_comments} \\ \hline
\textbf{cs} & \textbf{co} \\ \hline
rdfs:Class & "Class of classes" \\ \hline
ex:Leipzig & ex:City \\ \hline
\end{tabular}
\end{scriptsize}
\end{minipage}

\\

\bottomrule
\end{tabular}

\caption{A query and its expected result set when executed on the two given views and corresponding relations. The variables were chosen to be globally unique as to avoid name clashes.
For the example to work, the relations must hold full URIs, but they have been abbreviated in this figure for space reasons.}
\label{fig:running_example}
\end{figure}

\section{SPARQL-SQL Rewriting}
Our problem of SPARQL-SQL rewriting can be stated as:
Given a SPARQL query $q$, a set of Sparqlify view definitions $V$, a relational database $D$, obtain a pair $(s, m)$, where s is an SQL query, and $m$ is a set of variable bindings, i.e. a mapping from the SQL queries result-set to RDF. 
Thereby we make the following assumptions and observations:
\begin{itemize}
%  \item We aim at preserving the semantics of an RDF-terms underlying datatype: TODO This is an optimization
  \item The view names are considered to be unique.
  \item We assume the set of variables for all views and the query to be pair-wise disjoint.
		This can be achieved by renaming the variables, such as prefixing them with the name of the view.
		The reason is, that this eases the discussion as we can consider all variables sharing a global namespace without having to deal with name clashes or nested
		indexes.
  \item Every variable (of both the query and the views) may carry implicit and explicit constraints. 
		The former are those which are implied by the expression given either in the variable bindings or the query's FILTER expressions.
		The latter are the constraints explicitly stated in the constraint clause. 
		When processing a view definition, Sparqlify internally makes the implicit constraints explicit. 
		For example, consider a variable bindings such as:
		\begin{lstlisting}
			?s = uri(concat("http://ex.org/employee/", ?id))
		\end{lstlisting}
		By this we can infer constraints such as:
		\begin{lstlisting}
			startsWith(?s, "http://ex.org/employee/")
			regexPattern(?s, "http://ex.org/employee/[0-9]{0, 10}"
			    (assuming a 4 byte integer, it may yield up to 10 digits)
		\end{lstlisting}
		Based on this, a query optimizer can improve both the rewriting time of the SPARQL query (by ruling out unsatisfiable rewrites early)
		and the execution time of the corresponding SQL query. 
		For example, if Sparqlify encounters a JOIN condition, where two SPARQL variables are equated, it can check whether there exist corresponding startsWith-constraints. 
		If they exists, and neither startsWith-prefix is a substring of the other, Sparqlify can assume the expression to yield \emph{FALSE}. 
		As a consequence, the JOIN can be omitted without having to fetch data from the database.
%  \item \emph{Constant elimination}:
%		All constants that appear in the quad patterns of the original SPARQL query are
%		replaced by newly introduced variables, whereas these variables are constrained to the original
%		constant values via the addition of appropriate FILTER elements to the query. 
%		The result is, that \emph{all} constraints can be uniformly expressed by means of expressions over the query variables.
%  \todo{Make an image: query-> constraint->binding}
    
%	\item The \emph{essential} part in SPARQL-SQL query rewriting is to replace each quad-pattern of the query $q$ with a set of \emph{view-instances}.%
%		A view instance is a pair $(view, binding)$, where $view$ is a Sparqlify-ML view, and binding is a mapping from the query variables to the corresponding set of view variables.
  \item Once the quad patterns of the original SPARQL query have been expanded with the view instances, its SPARQL algebraic expression tree (AET) is successively transformed
		into an equivalent SQL AET in a bottom-up fashion.
		The AET nodes JOIN, LEFT JOIN, UNION and OPTIONAL directly translate to corresponding SQL nodes.
		Thereby the SPARQL expressions are being translated into equivalent SQL expressions. An important part of this translation is the bookkeeping of how
		the variables of the original query bind to the result-set of the rewritten SQL query.
  \item The final artefacts are the SQL expression and the mapping from the corresponding result set to the query-variables, from which a SPARQL result is generated.
\end{itemize}


\section{SPARQL and SQL algebra}
As already indicated in the previous section, our approach to rewriting of SPARQL queries is based on algebraic expression tree (AET) transformations. 
For both SPARQL and SQL there exist algebraic representations for the structure of queries besides their syntactic representation.
Note that an RDF graph, despite being called \emph{graph}, is according to its formal definition a triliteral (for triples) or quadrilateral (for quads) \emph{relation}.
The twist with RDF graphs is, that the columns have complex datatypes, such as the union of URIs, blanknodes and literals.
In this document we not
describe the differences of the two algebras in details, as we use a set of operators that is common to both of them.
There are subtle differences in the interpretation of the algebras, and in the representation of result sets.
For example a ``row'' in a SPARQL result set is a set of mappings from variable-names to their respective value, in SQL the variable corresponds to a column
and is part of the schema.
%\todo{Im VLBD paper explizit SPARQL und SQL algebra separat beschreiben}

%The purpose of the section is to give an overview of the most important
%ele. An analysis of \emph{all} elements of SPARQL

In the following the most important elements of the SPARQL 1.0 algebra\footnote{\url{http://www.w3.org/TR/rdf-sparql-query/}} are explained,
however, slightly adapted to the Sparqlify system.
\begin{itemize}
    \item \emph{pattern} The term pattern refers to any expression composed of the following components.
	%\item QUAD-PATTERN: A single quad pattern, i.e. a quad which may contain variables
	\item QUAD-PATTERN-SET: This is the most primitive pattern and is a set of quads.
		Although, formally such set is usually represented by nested JOINs of QUAD-PATTERNs, it turns out that a
		flat representation simplifies optimization, as the quads can be more easily re-arranged in different orders.
		Furthermore, the set nature automatically removes duplicate quad-patterns, which may occur e.g. due to automatic query generation. 
	\item JOIN(l, r): A join between two patterns $l$ and $r$.
	\item LEFT-JOIN(l, r): A left join between two patterns $l$ and $r$.
	\item UNION($u_1$, \ldots, $u_n$) Although formally usually a binary operator, in both Jena and our implementation a variable argument list turned out to be advantageous.
	\item FILTER(expr, a): A selection on the pattern $a$, which only retains those rows of the result set, that satisfy the predicate \emph{expr}.
	\item PROJECT(M, vars): A projection on the pattern $a$, which only retains the columns mentioned in \emph{vars}.
	\item DISTINCT(a): Removes any duplicate result rows.
\end{itemize}
For the SQL algebra, one essentially has to replace \emph{pattern} with \emph{relation}.
%\todo{I know this does not sound very scientific but for the deliverable I would just leave it like this.}
In fact, in terms of expressiveness both algebras have been proven to be equivalent~\cite{sparqloverrelational}. 

\begin{figure}[!h]
\centering
\begin{tabular}{ll}
\toprule
\emph{Syntax} & \emph{Algebra Expression} \\ 
\midrule

\begin{minipage}{6cm}
\begin{scriptsize}
\begin{verbatim}
Select Distinct ?s ?o {
  ?s ?t ?s .
  ?s rdfs:comment ?o .
}
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{6cm}
\begin{scriptsize}
\begin{verbatim}
Distinct (
  Project ((?s ?o), {
    QuadPatternSet({
        ?s ?t ?s .
        ?s rdfs:comment ?o
    })
) )
\end{verbatim}
\end{scriptsize}
\end{minipage}

\\

\bottomrule
\end{tabular}

\caption{Juxtaposition of a SPARQL query and its AET. The IRI for the default graph has been omitted in the quads.}
\label{fig:juxtapose-syntax-algebra}
\end{figure}

\section{Definitions}
Here we first define the most important concepts, and then present our approach to view candidate selection using our running example.
%\paragraph{RDF Graph}

\paragraph{Quad}
A \emph{quad} is in element of an RDF graph. We use the notion $q_i$ with $i \in I$ and $I := \left\{g, s, p, o \right\}$ to refer to a quad's $i$-th component. 

\paragraph{Binding and Binding Function}
A \emph{binding} $b$ is defined as a function $b \subseteq Var \rightarrow \Omega{ \left ( Var \cup Const \right ) }$.
%Furthermore we require the existance of a \emph{binding function} $b_f := $ for bindings.
%This implies, that 
%Furthermore we define $b$'s \emph{binding function} as $b_f(k) := \left \{ v | (k, v) \in b \right \}$
%In the remainder of this document, we use $b$ and $b_f$ interchangeably.
% is a mapping-function from variables to a set of variables and constants $B := Var \rightarrow  \Omega{ \left ( Var \cup Const \right ) }$.
%For an instance of a binding $b \subset B$, we use the notion $b(x)$ to refer to the set related to x.
In the following we always use bindings to map from \emph{query variables} to \emph{view variables} and constants.
Furthermore, we define helper functions with the goal of easing the operations on sets of variables:
\begin{itemize}
\item $\mathit{keys}(b, v) := \left\{ k | \exists k: v \in b(k) \right\}$ is the function that for a given variable (or constant) $v$ returns all the binding's keys that map to sets containing $v$.
\item $\mathit{Keys}(b, V) := \bigcup_{v \in V} \left \{ keys(b, v) \right \}$ is similar to above, however it takes a set of variables $V$ as the argument.
\item $\mathit{Values}(b, K) := \bigcup_{k \in K} \left \{ b(k) \right \}$ returns the union of the value-sets for a set of keys $K$.
\end{itemize}


\paragraph{Binding Merge}
Two bindings can be merged by combining all their mappings. $b_1 \oplus b_2 := \{q \rightarrow v | q \in {dom(b_1) \cup dom(b_2)}, v = b_1(q) \cup b_2(q)\}$.

\paragraph{Creation of Bindings}
In our system, bindings are always created from a pair of quads. We define $\beta$ as the function which creates a binding
by mapping the respective components of two quads $q$ and $r$:
 $\beta(q, r) = \bigoplus_{i \in I} \left \{q_i \rightarrow \left \{r_i \right \} \right \}$.

\paragraph{Binding Closure}
We use $b^*$ to denote the binding closure of a binding $b = b^0$, which is computed by
iteratively applying the following rule, until there are no more changes: We define $b^{i+1} := \bigcup_{k \in dom(b^i)} \left \{ k \rightarrow Values(b^i, Keys(b^i, b^i(k))) \right \}$
The binding closure is used to establish a mapping from a query variable to \emph{all} its related view variables.
Because view variables are associated with a set of constraints, the binding closure indirectly gives access to all contraints that must simultaneously apply to a query variable.
An example is shown in~\autoref{fig:binding-multimap}.

\paragraph{Constraint}
%\todo{Not sure if we should differ between constraint-level and rewrite level unsatisfiablity}
A constraint c is a predicate expression over a (possibly empty) set of variables.
Examples include
\begin{itemize}
\item $startsWith(?s, 'http://example.org')$
%\item $startsWith('http://dbpedia.org', 'http://example.org')$
\item inequality expressions, such as $?s > 5$
\item logical junctors, $\wedge, \vee, \lnot$
\item $true$ and
\item $false$.
\end{itemize}
We define $vars(c)$ as the set of variables mentioned in the predicate.


\paragraph{Restriction}
In contrast to constraints, which are \emph{expressions}, restrictions are \emph{functions} that indirectly express constraints.
Currently, Sparqlify supports prefix and rdf term type restrictions.
An example of a restriction is $prefixes: \left \{ ?s \rightarrow \left \{ "http://ex.org", "http://example.org") \right \} \right \}$.
They are used for indexing and looking up views. More detail are given in~\autoref{sec:optimized-candidate-selection}.
 

%\todo{Maybe we should talk about predicates; and let a constraint be something that exists independently of a var, such as [=5], or [>10]}

%\paragraph{Constraint Set}
%A \emph{constraint set} is a set of constraints. Thereby, unless noted otherwise, we assume that ``logical and'' holds between all members of such a set. 

%A binding can be converted to a set of EQUALS constraints, whereas EQUALS implied transitivity.
%For example, given \{?s -> \{rdf:type, ?a\}\} the constraints
%(?s = rdf:type), ?s = ?a.

%Given a set of constraints C and a binding B, B is inconsistent if any of its members evaluates to FALSE.

%We define the closure C* of C as the set of all constraints that can be inferred from C.
%For example, given {?s -> {rdf:type, ?a}}, we can additionally infer (?a = rdf:type hold).

%Note that if C* is empty, a binding can be inconsistent, if a same variable is transitively mapped to different constants.
%\todo{We may could do eval(my-constraints union C*) or eval(context-constraints, my-constraints). First seems better.}


\paragraph{View Instance}
A \emph{view instance} is a pair $(v, b)$, where a $v \in V$ is a Sparqlify-ML view and $b \in B$ is binding as defined above.
Such constructs are used for binding the variables of a query to those of a certain view.

\paragraph{Multi-View Instance}
We define a \emph{multi view instance} as a pair $(\mathfrak{v}, b)$, with $\mathfrak{v} \subseteq V$. 
This notion enables us to bind the variables of a query to those of a set of views using a single binding.
%Usually there are multiple view candidates for a single query quad.

%\paragraph{View to Multi-View Instance}
%This operator converts a view instance to a multi view instance.\todo{introduce the symbol}.


\paragraph{Multi-View Instance Merge}
We define an operator for merging two multi view instances. 
This yields a new multi view instance where all views and bindings were united, formally: 
$merge((\mathfrak{v}_a, b_a), (\mathfrak{v}_b, b_b)) =_{def} (\mathfrak{v}_a \cup \mathfrak{v}_b, b_a \oplus b_b)$
Note that a merge may yield an inconsistent binding, if a variable is mapped to two non-equal constants.

\paragraph{SqlNode}
%\todo{Leaf-SqlNodes are SqlQuery and SqlTableRef.}
An $SqlNode := (S, P, B)$ as an triplet consisting of:
\begin{itemize}
  \item a \emph{SQL algebra expression} $S$ which represents the relation.
  \item a \emph{projection} $P$, which maps column-names to SQL-expressions, similar to the AS keyword of SQL (\texttt{expr AS column-name})
  \item a \emph{variable definition} $B$, which expresses the SPARQL variables (of a query) as expressions over the column-names of $S$.
\end{itemize}
These entities are used in the SQL translation phase. 


\paragraph{Binding-level Unsatisfiability}
A binding is unsatisfiable, if any variable is mapped to multiple (i.e. non-equal) constants.
%Note that we do not consider constraints of the queries or the views at this stage.

\paragraph{Constraint-level Unsatisfiability}
Unsatisfiablity on the level of constraints on query and view variables (prefix and rdf-term-type constraints).
For instance, if two variables ?s and ?o are equated, where ?s is an uri and ?o a literal, the equation must always yield false.

\paragraph{Rewrite-level Unsatisfiability}
Unsatisfiability after having rewritten an expression to SQL.
For example consider this optimization: ?s = ?o, ?s = uri(``http://ex.org'', ?id), ?o = uri(``http://ex.org/'', ?name), and datatypes of
 id and name do not match. 



\section{Candidate View Selection}
It should be noted, that Sparqlify's approach for candidate view selection is largely inspired by~\cite{rewriting-queries-on-sparql-views}.
However, we have slightly improved some of the formalizations and introduced new optimizations.
%However,  which we briefly summarize here.
Given a query subject to rewriting, this query is first transformed into its equivalent SPARQL AET.
The leaf nodes are then all of type QUAD-PATTERN-SET.

\subsection{Query Constant Normalization}
The next step is to normalize all constants (i.e. literals and uris) from the quad-patterns of the query by replacing them
with newly allocated variables, which are constrained to the constant values through the introduction of appropriate filter operators.
This transformation offers two advantages:
First, it does not matter whether a constant appears in a quad pattern or whether a variable is equated to a constant in a filter clause. We only have to deal with the latter case.
Second, the use of variables enables us to associate constraints with them: Naturally, the original constant becomes one of its constraints.
However, in the process of binding the query variable to view variables, we are now also able to keep track of constraints inherited through the query-view binding.
By this we can for instance check whether a variable's set of constraints is inconsistent, and perform optimizations accordingly.   
\begin{figure}[!h]
\centering
\begin{tabular}{ll}
\toprule
\emph{Original Query} & \emph{Constants Normalized} \\ 
\midrule

\begin{minipage}{6cm}
\begin{scriptsize}
\begin{verbatim}
Distinct (
  Project ((?s ?o), {
    QuadPatternSet({
        ?s ?t ?s .
        ?s rdfs:comment ?o
    })
) )
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{6cm}
\begin{scriptsize}
\begin{verbatim}
Distinct (
  Project ((?s ?o), {
    Filter({v1 = rdfs:comment},
      QuadPatternSet({
        ?s ?t ?s .
        ?s ?v1 ?o
      })
) ) )
\end{verbatim}
\end{scriptsize}
\end{minipage}

\\

\bottomrule
\end{tabular}
\caption{Replacing constants of quad pattern sets with newly allocated variables which are constrained with appropriate filter operators.}
\label{fig:constant-removal}
\end{figure}

Note that the constant normalization could even be applied to the views, in which case any constants would be moved into the variable definitions.
This may lead to a slightly cleaner formalization, as bindings would no longer have to refer to constants, i.e. the definition of a
bindings would become $B := Var \rightarrow  \Omega{ \left ( Var \right ) }$.
An analysis of this point of view is left for future work.  


\subsection{Candidate Selection}
The basic idea is to perform a bottom-up traversal of such an AET and derive a new one by replacing all its QUAD-PATTERN-SETs with \emph{UNIONs of JOINs of candidate view-instances}.


\subsubsection{Algorithm for finding view candidates for QUAD-PATTERN-SETs}
\label{alg:canditate-finding}

Given a quad $p$ of the QUAD-PATTERN-SET $P$ and the set of views $V$, the naive approach for finding the candidate view instances $cand(p, V)$ is 
to compute for every $p$ all possible bindings to the quads of the views, and only retaining those that are not knowingly unsatisfiable, formally:
\begin{equation}\label{eq:candidate-set}
cand(p, V) = \bigcup_{v \in V} \left \{ (v, b) | q \in quads(v), b = \beta(p, q) and \lnot unsatisfiable(b) \right \}
\end{equation} 

~\autoref{tab:bindings} shows the bindings obtained for our running example. The query quad (?s ?v1 ?o) only has a single
non-inconsistent view-instance candidate, whereas (?s ?t ?s) has two such candidates.


\begin{table}[!h]
\centering
\begin{tabular}{|ll|cc|}
\toprule
& & \multicolumn{2}{|c|}{Bindings for the query quads} \\
\textbf{View} & \textbf{View Quad} & \textbf{?s ?t ?s} & \textbf{?s ?v1 ?o}  \\
\hline
types
&
?x rdf:type ?y
&
\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s = {?x, ?y}
?t = {rdf:type}
\end{verbatim}
\end{scriptsize}
\end{minipage}
& 
\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s = {?x}
?v1 = {rdf:type} (X)
?o = {?y}
\end{verbatim}
\end{scriptsize}
\end{minipage}
\\
\hline
comment
&
?h rdfs:comment ?i
&
\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s = {?h, ?i}
?t = {rdfs:comment}
\end{verbatim}
\end{scriptsize}
\end{minipage}
&
\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s = {?h}
?v1 = {rdfs:comment}
?o = {?i}
\end{verbatim}
\end{scriptsize}
\end{minipage}
\\
\bottomrule
\end{tabular}
\caption{View instances for the two query quads. The binding marked with (X) is inconsistent with the constraint ``?v1 = rdfs:comment'' which is imposed by the query.}
\label{tab:bindings}
\end{table}

\begin{equation}\label{eq:view-instance-join}
\mathfrak{C} = \times_{p \in P} cand(p, V)
\end{equation}


The next step is then to join each query quads candidate view instance set (~\autoref{eq:view-instance-join}). This yields a relation where each row contains view instances,
as shown in~\autoref{tab:view-instance-join-result}.
Each row will eventually result in a join of the instances' underlying SQL relations.



\begin{table}[!h]
\centering
\begin{tabular}{cccc}
\toprule
\textbf{?s ?t ?s} & & \textbf{?s ?v1 ?o} \\
\midrule

$A_1$: (types,
\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s = {?x, ?y}
?t = {rdf:type}
\end{verbatim}
\end{scriptsize}
\end{minipage}
)

&
&


\\

&
$\times$
&

$B_1$: (comment,
\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s = {?h}
?v1 = {rdfs:comment}
?o = {?i}
\end{verbatim}
\end{scriptsize}
\end{minipage}
)


\\

$A_2$: (comment,
\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s = {?h, ?i}
?t = {rdfs:comment}
\end{verbatim}
\end{scriptsize}
\end{minipage}
)

& 
&


\\
\bottomrule
\end{tabular}
\caption{Joining the obtained sets of candidate view instances. Every non-inconsistent combination of all candidates results is considered a join of the candidates. The set of all non-inconsistent combination is eventually translated into a union. Note that every combination can be checked for satisfiability after merging all the bindings.}
\label{tab:view-instance-join}
\end{table}


As an optimization, the final step is to prune all elements of $\mathfrak{C}$ that yield unsatisfiable join conditions, this is shown in
~\autoref{tab:view-instance-join-result}.
If this step was not applied, the rewritten SQL query would contain JOINS that yield empty result sets and are therefore unnecessary. 

\begin{table}
\centering
\begin{tabular}{cccc}
\toprule
\textbf{Combination} & \textbf{Result} & \textbf{Inconsistent?} \\
\midrule

$A_1 \times B_1$

&

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s = {?h, ?x, ?y}
?t = {rdf:type}
?v1 = {rdfs:comment}
?o = {?i}
\end{verbatim}
\end{scriptsize}
\end{minipage}


&

no

\\

\\
 
$A_2 \times B_1$

&

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s = {?h, ?i}
?t = {rdfs:comment}
?v1 = {rdfs:comment}
?o = {?i}
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

no

\\
\bottomrule
\end{tabular}
\caption{The result of joining the candidate view instances.}
\label{tab:view-instance-join-result}
\end{table}



\subsection{Optimized Candidate Selection}
\label{sec:optimized-candidate-selection}
The challenge with~\autoref{eq:candidate-set} is, how to \emph{efficiently} find the set of candidate view instances for a given query quad $p$.
Note that theses quads we are dealing with only consist of variables because of the constant normalization.

Our solution is based on deriving \emph{restrictions} from the \emph{constraints} that apply to the query and view variables.
Recall that constraints are predicate expressions, whereas restrictions are functions that map variables to objects.
Currently, Sparqlify supports the following two restrictions:
\begin{itemize}
  \item \emph{rdf-term-type restrictions} Let $T = \left \{blank, uri, plainLiteral, typedLiteral \right \}$ be the set of RDF term types. We define
  a term type restriction function as: $\mathfrak{t}: Var \rightarrow \Omega \left ( T  \right)$
  \item \emph{prefix restrictions} This function maps variables to the set of URI prefix strings. $\mathfrak{n}: Var \rightarrow \Omega \left( String \right)$
\end{itemize}
In the future, this may be extended to include for instance equals restrictions $equals: \left \{?p \rightarrow rdf:type \right\}$
or value range restrictions, such as $rangeRestriction: \left \{?age \rightarrow [0, 100] \right\}$.
Note that negated restrictions, such as ``does not have certain namespaces'' are currently not supported.


Deriving the restrictions for the variables of a view definitions is relatively simple:
\begin{itemize}
  \item Base on the term constructor of a variable definition, we can directly infer the variable's rdf term type restriction.
  \item The prefix restrictions can be directly derived from a view's startsWith constraints. Note that a prefix constraint implies a URI-term-type restriction. 
  \item As stated, startsWith constraints can be derived from URI term constructors whose argument either has the form \texttt{string-constant} or \texttt{concat(string-constant, \ldots)}.
  The restriction can then be derived in a separate step. 
\end{itemize}
We use these restrictions for indexing the views, as show in~\autoref{tab:view-index}. 


\begin{table}
\begin{scriptsize}
\begin{tabular}{|lllllllll|} \cline{1-2}
\multicolumn{2}{|c|}{view\_index} \\ \hline
\textbf{name} & \textbf{quad} & \textbf{s\_type} & \textbf{s\_pre} & \textbf{p\_type} & \textbf{p\_pre} & \textbf{o\_type} & \textbf{o\_pre} & \textbf{o\_lang} \\ \hline
types & ?x rdf:type ?y & uri & & uri & rdfs:type & uri & & \\
comments & ?h rdfs:comment ?i & uri & & uri & rdfs:comment & plainLiteral & & en \\
\bottomrule
\end{tabular}
\end{scriptsize}
\caption{Index table for the views of the running example. The ``Pre''-columns contain prefix constants that apply to the components (g, s, p, o) of the corresponding view-quad.
If a component in a quad has more than one prefix, the same view-quad may be indexed multiple times.}
\label{tab:view-index}
\end{table}


Deriving restrictions for a quad is more complex, as it requires analyzing all filter expressions that effect the quad in question.

Given a constraint expression $c$, we can infer the restrictions that apply to $vars(c)$ by:
\begin{enumerate}
  \item If $c$ is converted into conjunctive normal form (CNF), i.e. $\bigwedge_{i} \bigvee_{j} (\lnot) x_{ij}$,
  then we can derive ``global'' restrictions based on all single-literal-clauses, i.e clauses of the form $\left \{ (L right \right \}$.
  For instance, from a clause $\left \{ equals \left ( ?p, rdf:type \right ) \right \}$ we can derive that the prefix of ?p must \texttt{be rdf:type}.
  % Give a pointer on where it is used - i.e. pruning of join condiditions
  \item If $c$ is converted into the disjunctive normal form (DNF), i.e. $\bigvee_{i} \bigwedge_{j} (\lnot) x_{ij}$, then it is possible to derive
  constraints on a per-clause basis. We exploit this property to perform lookups of view candidates in the view index on a per-clause basis. 
\end{enumerate}



%\todo{Describe the lookup procedure}
Once we have obtained a set of views $V_q$ for a given query quad $q$, the next step to create the view instances.
Note that when binding the query variables to those of a view, the query variables inherits all constraints and restrictions that apply to the view variables.
The binding closure thereby helps to also capture indirect constraints: In the~\autoref{fig:binding-multimap} we see, that the closure additionally
adds $\left \{?a \rightarrow ?y \right \}$ and $\left \{?c \rightarrow ?x \right \}$, and therefore any restrictions on
$?x$ and $?y$ carry over to $?a$ and $?c$, respectively.
These new restrictions can then be used to make successive lookups more selective.


\begin{figure}[!h]
\centering
\begin{tabular}{llll}
\toprule
\emph{Query} & \emph{View} & \emph{Binding} & \emph{Binding Closure} \\ 
\midrule

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
Select * {
  ...
  ?a ?b ?b ?c
  ...
}
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
Create View example As
  Construct {
    ...
    ?x ?x ?y ?y
    ...
  }
  With ...
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?a -> { ?x }
?b -> { ?x, ?y }
?c -> { ?y }
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?a -> { ?x, ?y }
?b -> { ?x, ?y }
?c -> { ?x, ?y }
\end{verbatim}
\end{scriptsize}
\end{minipage}

\\

\bottomrule
\end{tabular}
\caption{Example of a binding of variable between a quad of the query and one of a view.}
\label{fig:binding-multimap}
\end{figure}


\subsubsection{Optimized View Candidate Selection Algorithm}
Having described how to perform an efficient lookup for a single query quad in the previous section, we here present our optimized approach
for finding candidate views for a quad pattern. 

Our optimized malgorithm for finding view candidates for a single QUAD-PATTERN-SET set proceeds as follows:

\begin{itemize}
  \item  Find the query quad pattern that we believe 
  \item Pick the quad that has the least number of consistent bindings.
  The rationale is, that as soon as a binding becomes inconsistent we can cut off searching this branch as any further JOIN will yield an empty result set. 
  \item Order the views that share most variables first. By this, the variables will inherit any constraints (from views and the query) early which gives a chance to quickly detect inconsistencies.
  If there are now more quads that share variables with the prior ones, pick the next one with the fewest candidates.
  \item By this we have now established an order on the query quads. The next step is to perform the JOIN as of~\autoref{eq:candidate-set} in this order. 
  however, this time we take all restrictions into account, and re-perform the lookups.
  Whenever restrictions become unsatisfiable, we can skip the building of current join candidate and advance to the next one.
  \item For every candidate binding $x$, recursively perform the following:
  \begin{itemize}
    \item If possible, take the next query-quad $q$, and perform a lookup for all its view candidates $V_q$ by considering all corresponding new and prior constraints.
    For each candidate, create a new binding $z$, by merging the prior bindings $x$ with the one to the the new candidate.
    If this binding new binding is inconsistent, try next view candidate.
	Otherwise, continue with the next query quad.
  \item If there is no next query quad, we have successfully created a set of candidate view instances whose bindings do not result in
	knowingly unsatisfiable join conditions. Add this set of instances to our result set.
  \end{itemize}
\end{itemize}

Following the algorithm in~\autoref{alg:canditate-finding}, we therefore start with the set of view instance candites of (?s ?v1 ?o).
%Then we perform the join between all candidate sets, as shown in ~\autoref{tab:view-instance-join} in order to retrieve a union of joins of view instances.
The result is depicted in~\autoref{tab:view-instance-join-result}. 



%and binding is a mapping from the query variables to the corresponding set of view variables. View instances enable multiple bindings of
%variables of the ``same view'', as it occurs when a view is a candidate for multiple query quads. 

%Note that the replacement of QUAD-PATTERN-SETS can be done independently of any non QUAD-PATTERN-SET operators, such as (LEFT) JOIN and UNION,
%although information from the parent nodes may be used for optimizations.

%A quad's context is where it appear in the query, an can be considered to be number, as assigned by a tree numbering scheme\todo{such as one of the XML node numbering schemes}.
%Given a QUAD-PATTERN-SET together, a context of where the quad pattern set appears in the AET, a constraint-set and a set of Sparqlify view definitions,
%we create a VIEW-INSTANCE-SET as follows:
%A view-instance set is a set of (nary) UNIONS of view instances.




%The goal is now to find for each query quad pattern the set of all candidate view instances
%whose virtual RDF graphs potentially contain solution bindings\footnote{According to the SPARQL specification, \url{http://www.w3.org/TR/rdf-sparql-query/}}.  
%ConcepFor achieving this, every quad of every view is matched against the query quad.

%\begin{definition}[Quad binding]
%A quad-binding is a set of mappings between the variables of the query and those of the views. Note that a query variable may bind
%to multiple view variables as
%Recall that we assume all variables to be in the same namespace and were renamed as to avoid name clashes.
%\end{definition}

%Given a SPARQL query string, we first parse it in order to obtain its syntactic form and further transform it into the respective algebra representation.
%Afterwards, we expand all QUAD PATTERN nodes with \emph{instances} of the view definition.
%The difference between a view definition and an instance of it is that the v \todo{complete sentence}


%In the general case, this binding is therefore a multimap as shown \autoref{fig:binding-multimap} \todo{contains a useless closing parenthesis ($c ->\ldots$)} : 
%This example shows a case, where the variable $?b$ of the query quad maps to the variables $?x$ and $?y$.
%The reason we bind in this direction (and not in the other way) is, that we need to create a query result set.
%The multimap means, that a variable of the query can bind to multiple variables in the same view. 
   

%Note that optimizations can also be done if the SPARQL query $q$ contained for instance \texttt{FILTER(?s = <http://ex.org>)}.
%In this case we can cross-check this equals constraint whether it is consistent with any \todo{complete sentence}


\subsection{Elimination of Self Joins}
A \emph{self join} situation occurs, if a set of view instances sharing the same view
is equivalent to a single view instance (using the same view) using an appropriate binding.
In other words: We are interested in detecting cases, where multiple bindings to the same view can be replaced by a single one.

\begin{figure}[!h]
\centering
\begin{tabular}{llll}
\toprule
\emph{Query} & \emph{View} & \multicolumn{2}{c}{Binding and inverse binding for the two view quads} \\ 
\midrule

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
Select * {
  ?s ?t ?s .
  ?s ?v ?o .
  
  Filter(?v = ....) .
}
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
Create View types As
  Construct {
     ?x rdf:type ?x .
     ?x ?c ?z .
  } With
      ...
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?s -> {?x}
?t -> {rdf:type}
----------------
?s -> {?x, ?z}
?v -> {?a}
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{3cm}
\begin{scriptsize}
\begin{verbatim}
?x -> {?s}
----------
?x -> {?s}
?z -> {?s}
?a -> {?v}
\end{verbatim}
\end{scriptsize}
\end{minipage}

\\

\bottomrule
\end{tabular}
\caption{Example for a self-join: A query against the given view can be answered directly by the view using an appropriate binding. There is no need for joins.}
\label{fig:running-example}
\end{figure}

Given a view instance set, we can detect and remove self-join using the algorithm in~\autoref{algo:self-join-check}.

\begin{figure}[!h]
\begin{lstlisting}
function checkMerge(viewInstanceA, viewInstanceB) {
    if(viewInstanceA.view != viewInstanceB.view) { return false; }

	// A binding maps query variables to sets of view variables
	// Get the inverse bindings, thus view-variable -> query variables
	inverseA = viewInstanceA.binding.inverse;
	inverseB = viewInstanceB.binding.inverse;
		
	// Now check if each parent variable in inverseA maps to the same
	// query variables as in inverseB
	// If that is the case, we have a self join
	for(viewVarA in inverseA.keys) {
	    queryVarsA = inverseA[viewVarA];
	    queryVarsB = inverseB[viewVarA];
	    
	    if(queryVarsB.isEmpty) { continue; }
	    
	    intersection = queryVarsA intersect queryVarsB; 
	    
	    // If the inverse bindings map one of the view variables
	    // to different query variable we cannot merge
	    if(intersection.isEmpty) { return false; }
	}
	
	return true;
}
\end{lstlisting}
\caption{Pseudo-code algorithm for checking whether bindings can be merged in order to remove self joins.}
\label{algo:self-join-check}
\end{figure}


%In the following we address the topics:
%\begin{itemize}
%  \item \emph{The SPARQL and SQL algebra}: Our rewriting process is based on converting a given SPARQL query string into its algebraic form, and then
%		substituting the quad patterns with view instances. 
%		A view instance is a pair \emph{}
%\end{itemize} 


\section{SQL Translation}
In this section we explain how the AET of the query which has been expanded with the view instances is translated to an SQL AET.
Sparqlify's approach is to perform a bottom-up traversal of the query AET and yield an appropriate \emph{SqlNode} at each SPARQL operator it encounters.
In the following we describe how view instances, JOINs and UNIONs are translated to SQL nodes.
%As we can see in the example, the leaf nodes of the AET are QPS({?s ?t ?s}) and QPS(?s ?p ?o). For the latter QPS additionally the constraint ?p = rdfs:comment holds.


\subsection{View Instance}
When translating a single view instance to an SqlNode, one has to take into account the constraints
inherited through bindings to appropriate SQL filter constraints:
Recall that in our example we have an instance of the view ``types'' with the binding $(?s = \{?x, ?y\}, ?t = \{rdf:type\})$
and the underlying SQL relation named ``sql\_types''.
The translation to an SqlNode is a follows:
The view definition of \texttt{types} contains the bindings $?x = uri(?ts)$ and $?y = uri(?to)$.
Because the binding equates $?s$ to both $?x$ and $?y$, it is implied that $?x$ must equal $?y$. 
By substituting $?x$ and $?y$ with their defining expressions, which are based on SQL columns, we eventually derive an SQL filter expression $ts = to$.
Furthermore, once $?x$ and $?y$ are constrained to be equal, it is sufficient to only retain one of the bindings for $?s$.

The translation and the resulting SQL AET are shown in~\autoref{fig:trans-view-instance}. 

\begin{figure}[!h]
\centering
\begin{tabular}{lll}
\toprule
\emph{View Instance} & \emph{Binding} & \emph{Translation}  \\ 
\midrule

\begin{minipage}{5cm}
\begin{scriptsize}
\begin{verbatim}
(
  bindings = {
    ?x = uri(?ts)
    ?y = uri(?to)
  },
  projection = {?ts -> _, ?to -> _},
  sql = {
    SqlTable("sql_types")
  }
)
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{4cm}
\begin{scriptsize}
\begin{verbatim}
?t = {rdf:type}

?s = { ?x, ?y }
  -> ?x = ?y
  -> uri(?ts) = uri(?to)
  
-> ?ts = ?to 
\end{verbatim}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{5cm}
\begin{scriptsize}
\begin{verbatim}
(
  bindings = {
    ?s = uri(?c_1)
    ?t = {rdf:type}
  },
  projection = {?c_1 = ts},
  sql = {
    SqlFilter({ts = to},
       SqlTable("sql_types")
    )
  }
)
\end{verbatim}
\end{scriptsize}
\end{minipage}

\\

\bottomrule
\end{tabular}
\caption{Translating the view instance to an SQL node according to the bindings. The underscore ``\_'' in the projection indicates an identity mapping.}
\label{fig:trans-view-instance}
\end{figure}

\newpage

\subsection{View-Instance-Set, Join and Left Join}
~\autoref{tab:view-instance-join-result} summarizes the two joins, $A_1 \times B_1$ and $A_2 \times B_1$, which we have to perform in order to answer our example query.
The involved views, and in consequence, the involved relations are \texttt{sql\_types} and \texttt{sql\_comments}, for which we have to create an appropriate join condition
based on the binding.
Thereby equals-expressions are formed for every set of view variables in the binding, whereas the variables are then substituted with their definitions and afterwards rewriting rules are
applied which yield SQL expressions.
Note that because all view variables in such set need to be equal,
we can create a logical conjunction of equals expressions obtained by
picking one of the variables and equating it to each of the remaining ones.
In our example, only ?s maps to multiple variables, and results in the join condition $(?cs = ?ts) \&\& (?cs = ?to)$ as shown in~\autoref{fig:join-rewrite-expr}. 
Similarly, in the case $A_2 \times B_1$ the view variables $?h$ and $?i$ are equated, leading to uri(?cs) = plainLiteral(?co), and eventually false.
This means, that the second join does not have to be considered for our query, which means that a single JOIN is sufficient for answering the
first part of the query.



Joining two SqlNodes requires the derivation of appropriate JOIN conditions for any variables they have in common.
Since variables may have multiple alternative definitions, such as introduced by unions, the overall structure of
the join condition becomes a DNF. The algorithm is shown in~\autoref{alg:join}, whereas its application on the
running example is shown in \autoref{fig:join-rewrite-expr}.
The final SQL query and mapping for our example is obtained when serializng the relation algebra expression as an SQL query string is shown in ~\autoref{fig:rewrite-final-result}.

\begin{figure}[!h]
\begin{scriptsize}
\begin{lstlisting}
?s = {uri(cs)}
?t = {rdf:type}
?v1 = {rdfs:comment} 
?o = {uri(co}}
SELECT a_1.cs, a_2.co FROM sql_types a_1 JOIN sql_comments a_2
    WHERE (a_1.cs = a_2.co) AND (a_2.cs = a_2.to);
\end{lstlisting}
\end{scriptsize}
\caption{The final binding and SQL query after rewriting the query of the running example.}
\label{fig:rewrite-final-result}
\end{figure}


\begin{figure}[!h]
\begin{tabular}{ccc}
\toprule
SQL & Projection & Binding \\
\midrule

$\sigma_{cs = co} \left ( sql\_types \times sql\_comments \right )$

&

Identity

&

\begin{minipage}{5cm}
\begin{scriptsize}
\begin{verbatim}
?s = {uri(a_1.cs)}
?t = {rdf:type}
?v1 = {rdfs:comment} 
?o = {plainLiteral(a_2.co)}
\end{verbatim} 
\end{scriptsize}
\end{minipage}

\\
\bottomrule
\end{tabular}
\caption{The state of the SqlNode obtained after rewriting the QUAD-PATTERN-SET of the running example.}
\end{figure}

\begin{figure}
\begin{lstlisting} 

foreach(variable v common to both A and B) {
	dnf = {};
    foreach(definition dA in defs(A, v)) {
    
    	and_clauses = {};
    	foreach(definition dB in defs(B, v)) {
    		and_clauses.add(rewrite(Equals(dA, dB)));
    	}
    	
    	dnf.add(and_clauses);
    }
}
\end{lstlisting}
\caption{Algorithm for deriving a DNF of join condiditons based on the defining expressions of all shared variables.}
\label{alg:join}
\end{figure}


\begin{figure}[!h]
\begin{scriptsize}
\begin{lstlisting}
Variable Definitions of the views 'types' and 'comment':
types:    ?x = uri(?ts) = rdfterm(1, ?ts, '', '')
          ?y = uri(?to) = rdfterm(1, ?to, '', '')

comments: ?h = uri(?cs) = rdfterm(1, ?cs, '', '')
          ?i = plainLiteral(?co) = rdfterm(2, ?co, '', '')

Binding for B_1:
    ?s = {?h}
    ?v_1 = {rdfs:comment}
    ?o = {?i}

Binding for A_1:
    ?s = {?x, ?y}
    ?t = {rdf:type}

Binding for A_2:
      ?s = {?h, ?i}
      ?t = {rdfs:comment}

For A_1 x B_1 (types x comment):
    Common variables: {?s}
    Join condition therefore is: (?h = ?x) AND (?h = ?y)    

Substituting the variables with the corresponding definitons
and rewriting yields:
?h = ?x:
    (rdfterm(1, ?cs, '', '') = rdfterm(1, ?ts, '', '')) 
    (1 = 1 && ?cs = ?ts && '' == '' && '' == '' &&) 
    (true && ?cs = ?ts && true && true) 
    (?cs = ?ts)

?h = ?y:
    (rdfterm(1, ?cs, '', '') = rdfterm(1, ?to, '', ''))
    (1 == 1 && ?cs = ?to && '' == '' && '' == '' &&)
    (true && ?cs = ?to && true && true)
    (?cs = ?to)
    
-> (?cs = ?ts) AND (?cs = ?to)

For A_2 x B_1 (comment x comment):
    Common variables: {s}
    Join condition therefore is: ?h = ?h OR ?h = ?i  

Substituting the variables with the corresponding definitons
and rewriting yields:
    ?h = ?i
    uri(?cs) = plainLiteral(?co)
    rdfterm(1, ?cs, '', '') = rdfterm(2, ?co, '', '')
    (1 == 2 && ?cs == ?co && true && true) 
->  FALSE

\end{lstlisting}
\end{scriptsize}
\caption{Rewrite of the join condititions for $A_1 \times B_1$ and $A_2 \times B_2$. The latter gives FALSE, which means that the join can be
pruned. As a result, only a single JOIN needs to be included in the resulting SQL algebra and consequently in the final SQL query string. }
\label{fig:join-rewrite-expr}
\end{figure}

%A note on Join and Left Join: Joins occur between using sub-queries.


\subsection{Union}
A union of two or more SqlNodes, $Union(s_1, s_2, \ldots, s_n)$ conceptually results in the outer union of all
the union's members, thereby updating the column references to the new projection and taking the binding merge of all involved variable bindings.

A noteworthy thing about unions is, that they can lead to multiple bindings for the same variable:
This case arises when two or more of its members define variable bindings for the same variable, such as one member with $?s = uri(?workpage)$ and another with $?s = uri(?age)$.
Naturally, each of these bindings is only valid for the subset of the union's result set, which was contributed by the respective member.
In order to disambigate which bindings to apply, we can exploit the property of having taken the outer union. This ensures that all columns not originally belonging to a member will be filled with NULLs.
Therefore, given a tuple of the union, any binding for which any of its referenced columns is NULL does not apply. Note that in the case of LEFT-JOINs it may happen that none of the bindings
apply\footnote{Another case where this can happen is, if a view definition references columns containing NULL values. Although, strictly speaking, such mapping is invalid, as it does not yield a valid RDF graph, Sparqlify allows it.}, which
results in an unbound RDF term.
Special treatment has been done with bindings to constants, such as $?o = typedLiteral($``$5$''$, xsd:double)$: In order to discriminate for member they apply,
they are pushed into columns of appropriate data type into the respective member-relation. The binding is then updated accordingly, such as $?o = plainLiteral(?autoGeneratedColumnOfTypeDouble, xsd:double)$.


One reasonable optimization is to reduce the number of columns a full outer union would generate, by factoring out structural equivalent binding expressions, and assigning them the same set of columns.


%\todo{If time gets too short we can just leave it at that and remove the rest.}
%\paragraph{Structural Equivalence of Expressions} We define the structural equivalence, structEquiv(a, b) of two expressions as follows:\todo{Use partial function style?}
%\begin{enumerate}
%  \item true if either a and b are leaf nodes, and datatype(a) == datatype(b)
%  \item a and b have the same operator and same number of arguments, and each pair of arguments is structural equivalent.\todo{Meh, I know this can be expressed in such a nice way, but I can't think of it} 
%  \item false otherwise.
%\end{enumerate}
%The idea is, that we can ``factor out'' structural equivalent expressions of variable definitions in order to reduce the number of columns.

%Additionally, meh. man kann halt gemeinsame ausdrueke rausfaktorisieren und kommt daher mit weniger spalten aus.
%- Structural equivalent expressions (leaf nodes (variables and constants) are replaced by their datatype) 



%\begin{verbatim}
%SELECT a_1.cs, a_2.co FROM sql\_types a_1 JOIN sql\_comments a_2 
%  WHERE a_1.cs = a_2.co;\todo{ref this statement in prev section}
%\end{verbatim}

\begin{figure}[!h]
\begin{tabular}{ccc} \toprule
Types' SqlNode & Comment's SqlNode & Union's SqlNode \\ \midrule

\begin{minipage}{3.5cm}
\begin{scriptsize}
\begin{verbatim}
?s = {uri(?ts)}
?p = {rdf:type} 
?o = {uri(?to)}
\end{verbatim} 
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{4.5cm}
\begin{scriptsize}
\begin{verbatim}
?s = {uri(?cs)}
?p = {rdfs:comment}
?o = {plainLiteral(?co)}
\end{verbatim}
\end{scriptsize}
\end{minipage}


&

\begin{minipage}{5cm}
\begin{scriptsize}
\begin{verbatim}
?s = {uri(?s)}
?p = {uri(?p}}
?o = {uri(?o_1), plainLiteral(?o_2)}
\end{verbatim}
\end{scriptsize}
\end{minipage}


\\

\begin{minipage}{3.5cm}
\begin{scriptsize}
\begin{tabular}{|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{sql\_types} \\ \hline
\textbf{ts} & \textbf{to} \\ \hline
rdfs:Class & rdfs:Class \\ \hline
ex:car123 & ex:Car \\ \hline
\end{tabular}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{4.5cm}
\begin{scriptsize}
\begin{tabular}{|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{sql\_comments} \\ \hline
\textbf{cs} & \textbf{co} \\ \hline
rdfs:Class & "Class of classes" \\ \hline
ex:Leipzig & ex:City \\ \hline
\end{tabular}
\end{scriptsize}
\end{minipage}

&

\begin{minipage}{5cm}
\begin{tiny}
\begin{tabular}{|l|l|l|l|} \cline{1-2}
\multicolumn{2}{|c|}{union} \\ \hline
\textbf{s} & \textbf{o\_1} & \textbf{o\_2} & \textbf{p} \\\hline
rdfs:Class & rdfs:Class & & rdf:type \\ \hline
ex:car123 & ex:Car & & rdf:type \\ \hline
rdfs:Class & & "Class of classes" & rdfs:comment\\ \hline
ex:Leipzig & & ex:City & rdfs:comment \\ \hline
\end{tabular}
\end{tiny}
\end{minipage}


\\ \bottomrule



\end{tabular}
\caption{The resulting SqlNode after optimizing the outer union yeld by processing the query \texttt{Select * \{ ?s ?p ?o \}} on the given views.
Because all variable definitions of ?s were structurally equivalent, they could be combined into the same column.
The predicate URIs had to be pushed into columns (of type string) into the respective member as to discriminate them.
The corresponding columns could then be collapsed aswell because of structurally equivalent variable definitions.
The object columns could not be further optimized. Note that the column names of the projection are usually automatically assigned by the system. Here we have labeled them for clarity.}
\end{figure}

  



\subsection{Sparql Result Set Creation}
The result of the SPARQL-SQL rewrite is a pair consisting of an algebraic SQL expression and a set of variable bindings.
The raw SQL expression is traversed, and the various AET types, such as JOINs, FILTERs, SLICEs, PROJECTIONs, are
condensed into appropriate SQL-SELECT-BLOCKS. These are structured representations of an SQL SELECT statement, as shown in \autoref{fig:sql-select-block}.
This new structure can then be serialized as an SQL query string. Finally, the SQL query (string) is sent to the DBMS for execution.
By evaluating the expressions of the variable bindings for each row of the result set, we obtain a SPARQL result set.  

%The SPARQL specification defines the query forms SELECT, ASK, CONSTRUCT and DESCRIBE. However, w  
Note, that we only need to be able to rewrite SPARQL SELECT queries, as the other query types can be expressed by  them as follows:

\begin{itemize}
\item \emph{CONSTRUCT}: A construct query can be treated as a SELECT query, where each row of the result set instantiates the CONSTRUCT pattern.
	The projection of the SELECT query only needs to contain those variables that are mentioned in the CONSTRUCT-template.
	Triples with invalid bindings, such as NULL or literals in the subject position, are omitted.
\item \emph{ASK}: This is equivalent to firing a SELECT query and determining whether the result set is not empty. 
	For efficiency, Sparqlify appends a \texttt{LIMIT 1} to the corresponding SELECT query. 
\item \emph{DESCRIBE}: This is the most complex query to express in terms of a set of SELECT statements. 
	Things that need to be considered are: DESCRIBE queries may contain a WHERE clause and any combination of constants and variables may be subject to the description.
	Furthermore, the SPARQL specification does not define of which triples make up the description of a resource\footnote{\url{http://www.w3.org/TR/rdf-sparql-query/\#describe}},
	and instead leaves the choice to the query processor.
	Several descriptions are used in practice.\footnote{\url{http://answers.semanticweb.com/questions/1648/how-is-sparql-describe-used-in-practice}}
	Sparqlify currently only supports the one that yields the triples whose subjects match the resources to be described.    
\end{itemize}


\section{Conclusion and Future Work}
In this deliverable we presented the \emph{Sparqlify} project, which comprises
\begin{itemize}
  \item The simple, yet powerful mapping language \emph{Sparqlify-ML} that reuses familiar elements of the SPARQL grammar
  in order to lower the learning curve and ease the manual writing of view definitions.
  \item The command line tool \emph{sparqlify-csv}, which uses essentially the same mapping language for transforming CSV files to RDF. 
  \item The SPARQL-SQL rewriter engine, which generates optimized SQL queries using unsatisfiablity checks and self join elimination.   
\end{itemize}

Sparqlify has been successfully deployed in the LinkedGeoData project on the
OpenStreetMap\footnote{\url{http://www.openstreetmap.org/}}
database\footnote{Using the ``simple schema'' provided and supported by the respective OpenStreetMap tools.},
where it gives access to more than 20 billion triples backed by about 3 billion physical rows.
There are also use cases related to linguistic resources.
One is the mapping of the Wortschatz database\footnote{\url{www.wortschatz.uni-leipzig.de/}}, where the virtual RDF contains reified statements, which however can be maintained and queried efficiently with the Sparqlify system.
%The other is PanLex\todo{ask Seppl for one sentence about it.}.


While initial benchmark results with the BSBM\footnote{\url{http://www4.wiwiss.fu-berlin.de/bizer/berlinsparqlbenchmark/}} indicates a performance comparable with D2R, a thorough benchmark yet needs to be performed.
A research question is how the SPARQL 1.1 features\footnote{\url{http://www.w3.org/TR/sparql11-query/}}, such as property paths of arbitrary length, can be efficiently supported in SPARQL-SQL rewriters.
Furthermore, although we believe that Sparqlify-ML is easier to use while offering the very similar functionality as the RDF based mapping language R2RML\footnote{\url{http://www.w3.org/TR/r2rml/}},
the latter has been standardized very recently and should therefore be supported by the Sparqlify system. Yet, we believe that
Sparqlify-ML is in most cases easier to learn and use than R2RML, and therefore see future efforts on improving Sparqlify-ML as complementary. 

It is also noteworthy, that Sparqlify-ML was designed with the goal to enable SPARQL-SQL rewriting.
Therefore its language features for data transformation are limited to simple functions,
such as concat and urlEncode/urlDecode.
However, one can distinguish between mapping languages intended for query rewriting and ones intended for
ETL, whereas the latter may extend the former.
The Google Refine RDF extension, which similar to Sparqlify-csv enables the RDF conversion of CSV files,
demonstrates this, by offering users besides powerful tools, such as reconciliation, to transform cell values using the powerful Google Refine Expression Language (GREL).  
The Google RDF extension only offers a graphical interface for the specification of the RDF skeleton, however, power users
may also benefit from a Sparqlify-ML integration.


\chapter{Appendix}
\section{Sparqlify-ML Config File Syntax (Informative)}
\label{sec:spec:sparqlify-ml-syntax}
%\todo{Separate between the view definition syntax and the config file syntax. Sparqlify-ML refers to the whole language}
The following ANTLR excerpt summarizes the additions introduced by Sparqlify to the SPARQL grammar of the sparkle-g project\footnote{\url{http://code.google.com/p/sparkle-g/}}.
\begin{lstlisting}
sparqlifyConfig
    : sparqlifyConfigStmt+ EOF!
    ;

sparqlifyConfigStmt 
    : viewDefStmt
    | prefixDefStmt
    ;

viewDefStmt
    : CREATE VIEW NAME AS CONSTRUCT
          viewTemplateDef varConstraintsClause? (FROM relationRef)? ';'?
    ;

varConstraintsClause
    : CONSTRAIN varConstraint+
    ;

varConstraint
    : prefixValueConstraint
    ;


prefixValueConstraint
    : var PREFIX stringList
    ;

stringList
    : string (COMMA? string)*
    ;

viewTemplateDef
	: constructTemplate varBindingPart?
	;


prefixDefStmt
    : prefixDecl
    ;
    

relationRef
    : SQL_QUERY
    | NAME
    ;

varBindingPart
    : WITH varBindingItem+ -> ^(VAR_BINDINGS varBindingItem+)
    ;


varBindingItem
    : var '=' typeCtorExpression
    ;	

typeCtorExpression
    : BNODE '(' expression ')'
    | URI '(' expression ')'
    | PLAIN_LITERAL '(' expression (',' expression)? ')'
    | TYPED_LITERAL '(' expression ',' expression ')'
    ;
\end{lstlisting}




\bibliographystyle{plain}
\bibliography{literature}

\end{document}
